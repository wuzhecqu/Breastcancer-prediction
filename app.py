import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import warnings
warnings.filterwarnings('ignore')

# ------------------ é¡µé¢é…ç½® ------------------
st.set_page_config(
    page_title="ä¹³è…ºç™Œè¯Šæ–­é¢„æµ‹ä¸è§£é‡Šç³»ç»Ÿ",
    page_icon="ğŸ©º",
    layout="wide"
)

# ------------------ åŠ è½½æ¨¡å‹å’Œè§£é‡Šå™¨ (ç¼“å­˜) ------------------
@st.cache_resource
def load_artifacts():
    """åŠ è½½æ¨¡å‹ã€æ ‡å‡†åŒ–å™¨ã€SHAPè§£é‡Šå™¨å’Œç‰¹å¾ä¿¡æ¯"""
    try:
        # åŠ è½½æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
        model = joblib.load('lightgbm_model.pkl')
        scaler = joblib.load('scaler.pkl')
        
        # åŠ è½½ç‰¹å¾ä¿¡æ¯
        with open('feature_info.json', 'r', encoding='utf-8') as f:
            feature_info = json.load(f)
        
        # è·å–é€‰ä¸­çš„ç‰¹å¾
        selected_features = feature_info.get('selected_features', [
            'radius_worst', 'concave points_mean', 'radius_se',
            'concavity_worst', 'area_worst', 'compactness_mean'
        ])
        
        # åˆ›å»ºèƒŒæ™¯æ•°æ®ç”¨äºSHAPè§£é‡Šå™¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨é›¶çŸ©é˜µï¼‰
        background = pd.DataFrame(
            np.zeros((10, len(selected_features))),
            columns=selected_features
        )
        background_scaled = scaler.transform(background)
        
        # åˆ›å»ºSHAPè§£é‡Šå™¨
        explainer = shap.TreeExplainer(model, background_scaled, model_output='probability')
        
        # è·å–æœŸæœ›å€¼ï¼ˆé¢„æµ‹æ¶æ€§æ¦‚ç‡çš„åŸºç¡€å€¼ï¼‰
        # å¯¹äºäºŒåˆ†ç±»ï¼Œexpected_value[1] æ˜¯æ¶æ€§ç±»çš„åŸºç¡€æ¦‚ç‡
        expected_val = explainer.expected_value
        
        # å¤„ç†expected_valueçš„æ ¼å¼
        if isinstance(expected_val, np.ndarray) and len(expected_val) > 1:
            base_value = expected_val[1]  # æ¶æ€§ç±»çš„åŸºç¡€å€¼
        else:
            base_value = float(expected_val) if isinstance(expected_val, np.ndarray) else float(expected_val)
        
        return model, scaler, explainer, base_value, feature_info, selected_features
        
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹ç»„ä»¶å¤±è´¥: {e}")
        # è¿”å›é»˜è®¤å€¼
        selected_features = [
            'radius_worst', 'concave points_mean', 'radius_se',
            'concavity_worst', 'area_worst', 'compactness_mean'
        ]
        return None, None, None, 0.0, {}, selected_features

# åŠ è½½æ¨¡å‹ç»„ä»¶
model, scaler, explainer, base_value, feature_info, selected_features = load_artifacts()

# ------------------ ä¾§è¾¹æ ï¼šç”¨æˆ·è¾“å…¥ ------------------
st.sidebar.header("ğŸ”¬ è¾“å…¥æ‚£è€…ç‰¹å¾å€¼")

# ä¸ºæ¯ä¸ªç‰¹å¾åˆ›å»ºè¾“å…¥æ»‘å—
feature_inputs = {}
for feat in selected_features:
    # æ ¹æ®ç‰¹å¾å®šä¹‰åˆç†çš„èŒƒå›´å’Œé»˜è®¤å€¼
    if feat == 'radius_worst':
        min_val, max_val, default_val, step_val = 10.0, 30.0, 15.0, 0.1
    elif feat == 'concave points_mean':
        min_val, max_val, default_val, step_val = 0.0, 0.2, 0.05, 0.001
    elif feat == 'radius_se':
        min_val, max_val, default_val, step_val = 0.2, 2.0, 0.5, 0.01
    elif feat == 'concavity_worst':
        min_val, max_val, default_val, step_val = 0.0, 0.5, 0.1, 0.01
    elif feat == 'area_worst':
        min_val, max_val, default_val, step_val = 500.0, 2000.0, 800.0, 10.0
    elif feat == 'compactness_mean':
        min_val, max_val, default_val, step_val = 0.05, 0.3, 0.15, 0.001
    else:
        min_val, max_val, default_val, step_val = 0.0, 1.0, 0.5, 0.01
    
    # åˆ›å»ºæ»‘å— - ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ˜¯floatç±»å‹
    value = st.sidebar.slider(
        label=f"{feat}",
        min_value=float(min_val),
        max_value=float(max_val),
        value=float(default_val),
        step=float(step_val),
        help=f"èŒƒå›´: {min_val} - {max_val}"
    )
    feature_inputs[feat] = value

st.sidebar.markdown("---")
predict_button = st.sidebar.button("ğŸš€ è¿›è¡Œè¯Šæ–­é¢„æµ‹", type="primary", use_container_width=True)

# ------------------ ä¸»é¡µé¢ ------------------
st.title("ğŸ©º ä¹³è…ºç™Œè¯Šæ–­é¢„æµ‹ä¸å¯è§£é‡Šæ€§åˆ†æ")
st.markdown("åŸºäºLightGBMæ¨¡å‹çš„ä¹³è…ºç™Œè‰¯æ¶æ€§é¢„æµ‹ç³»ç»Ÿï¼Œæä¾›SHAPå¯è§£é‡Šæ€§åˆ†æã€‚")

if predict_button and model is not None:
    with st.spinner('æ­£åœ¨åˆ†æç‰¹å¾å¹¶ç”Ÿæˆé¢„æµ‹...'):
        try:
            # 1. å‡†å¤‡è¾“å…¥æ•°æ®
            input_df = pd.DataFrame([feature_inputs])
            input_df = input_df[selected_features]  # ç¡®ä¿åˆ—é¡ºåº
            input_scaled = scaler.transform(input_df)
            
            # 2. è¿›è¡Œé¢„æµ‹
            probability = model.predict(input_scaled, raw_score=False)[0]  # è·å–æ¦‚ç‡
            prediction = 1 if probability > 0.5 else 0
            prediction_label = "æ¶æ€§ (M)" if prediction == 1 else "è‰¯æ€§ (B)"
            
            # 3. è®¡ç®—SHAPå€¼
            shap_values = explainer.shap_values(input_scaled)
            
            # å¤„ç†SHAPå€¼çš„æ ¼å¼
            if isinstance(shap_values, list):
                # å¯¹äºäºŒåˆ†ç±»ï¼Œshap_values[1] å¯¹åº”æ¶æ€§ç±»
                shap_val_for_instance = shap_values[1][0]
            else:
                shap_val_for_instance = shap_values[0]
            
            # ------------------ æ˜¾ç¤ºé¢„æµ‹ç»“æœ ------------------
            st.header("ğŸ“Š é¢„æµ‹ç»“æœ")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                if prediction == 1:
                    st.error(f"**é¢„æµ‹åˆ†ç±»: {prediction_label}**")
                else:
                    st.success(f"**é¢„æµ‹åˆ†ç±»: {prediction_label}**")
            
            with col2:
                st.metric(label="**æ¶æ€§æ¦‚ç‡**", value=f"{probability:.2%}")
            
            with col3:
                # é£é™©ç­‰çº§
                if probability < 0.2:
                    risk = "ä½é£é™©"
                    color = "green"
                elif probability < 0.6:
                    risk = "ä¸­é£é™©"
                    color = "orange"
                else:
                    risk = "é«˜é£é™©"
                    color = "red"
                st.markdown(f"**é£é™©ç­‰çº§**: :{color}[{risk}]")
            
            # é¢„æµ‹æ¦‚ç‡è¿›åº¦æ¡
            st.progress(float(probability), text=f"æ¶æ€§æ¦‚ç‡: {probability:.2%}")
            
            # ------------------ SHAPåŠ›åŠ›å›¾ ------------------
            st.header("ğŸ§  æ¨¡å‹å†³ç­–è§£é‡Š (SHAPåŠ›åŠ›å›¾)")
            st.markdown(f"**åŸºç¡€å€¼**: {base_value:.4f} (æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„å¹³å‡é¢„æµ‹)")
            
            # åˆ›å»ºåŠ›åŠ›å›¾
            fig, ax = plt.subplots(figsize=(10, 4))
            
            # åˆ›å»ºforce_plot
            shap.force_plot(
                base_value=base_value,
                shap_values=shap_val_for_instance,
                features=input_df.iloc[0],
                feature_names=selected_features,
                matplotlib=True,
                show=False,
                text_rotation=15
            )
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.clf()
            
            # ------------------ ç‰¹å¾å½±å“åˆ†æ ------------------
            st.header("ğŸ“ˆ ç‰¹å¾å½±å“åˆ†æ")
            
            # åˆ›å»ºç‰¹å¾å½±å“DataFrame
            impact_df = pd.DataFrame({
                'ç‰¹å¾': selected_features,
                'SHAPå€¼': shap_val_for_instance,
                'ç‰¹å¾å€¼': input_df.iloc[0].values,
                'ç»å¯¹å½±å“': np.abs(shap_val_for_instance),
                'å½±å“æ–¹å‘': ['å¢åŠ é£é™©' if v > 0 else 'é™ä½é£é™©' for v in shap_val_for_instance]
            })
            
            # æŒ‰ç»å¯¹å½±å“æ’åº
            impact_df = impact_df.sort_values('ç»å¯¹å½±å“', ascending=False)
            
            # æ˜¾ç¤ºè¡¨æ ¼
            st.dataframe(
                impact_df[['ç‰¹å¾', 'ç‰¹å¾å€¼', 'SHAPå€¼', 'å½±å“æ–¹å‘']].style.format({
                    'ç‰¹å¾å€¼': '{:.3f}',
                    'SHAPå€¼': '{:.4f}'
                }),
                use_container_width=True
            )
            
            # ------------------ å¯è§†åŒ–ç‰¹å¾å½±å“ ------------------
            fig = go.Figure()
            
            # æ·»åŠ æ¡å½¢å›¾
            colors = ['red' if x > 0 else 'blue' for x in impact_df['SHAPå€¼']]
            
            fig.add_trace(go.Bar(
                x=impact_df['SHAPå€¼'],
                y=impact_df['ç‰¹å¾'],
                orientation='h',
                marker_color=colors,
                text=[f'{x:.4f}' for x in impact_df['SHAPå€¼']],
                textposition='auto',
                name='SHAPå€¼'
            ))
            
            fig.update_layout(
                title='å„ç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“ (SHAPå€¼)',
                xaxis_title='SHAPå€¼ (å¯¹æ¶æ€§æ¦‚ç‡çš„å½±å“)',
                yaxis_title='ç‰¹å¾',
                height=400,
                showlegend=False
            )
            
            # æ·»åŠ é›¶çº¿
            fig.add_vline(x=0, line_width=1, line_dash="dash", line_color="black")
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ------------------ ä¸´åºŠå»ºè®® ------------------
            st.header("ğŸ’¡ ä¸´åºŠè§£è¯»ä¸å»ºè®®")
            
            # æ‰¾å‡ºæœ€é‡è¦çš„é£é™©å› ç´ å’Œä¿æŠ¤å› ç´ 
            top_risk = impact_df[impact_df['SHAPå€¼'] > 0].head(2)
            top_protective = impact_df[impact_df['SHAPå€¼'] < 0].head(2)
            
            col_a, col_b = st.columns(2)
            
            with col_a:
                st.subheader("ä¸»è¦é£é™©å› ç´ ")
                if not top_risk.empty:
                    for _, row in top_risk.iterrows():
                        st.markdown(f"**{row['ç‰¹å¾']}** = {row['ç‰¹å¾å€¼']:.3f}")
                        st.markdown(f"è´¡çŒ®: +{row['SHAPå€¼']:.4f} (å¢åŠ æ¶æ€§é£é™©)")
                else:
                    st.info("æœªè¯†åˆ«å‡ºæ˜æ˜¾çš„é£é™©å› ç´ ")
            
            with col_b:
                st.subheader("ä¸»è¦ä¿æŠ¤å› ç´ ")
                if not top_protective.empty:
                    for _, row in top_protective.iterrows():
                        st.markdown(f"**{row['ç‰¹å¾']}** = {row['ç‰¹å¾å€¼']:.3f}")
                        st.markdown(f"è´¡çŒ®: {row['SHAPå€¼']:.4f} (é™ä½æ¶æ€§é£é™©)")
                else:
                    st.info("æœªè¯†åˆ«å‡ºæ˜æ˜¾çš„ä¿æŠ¤å› ç´ ")
            
            # å»ºè®®
            st.subheader("åç»­æ­¥éª¤å»ºè®®")
            if probability > 0.7:
                st.warning("""
                **å¼ºçƒˆå»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥ï¼š**
                1. ç«‹å³å’¨è¯¢ä¹³è…ºå¤–ç§‘æˆ–è‚¿ç˜¤ç§‘ä¸“å®¶
                2. è€ƒè™‘è¿›è¡Œç©¿åˆºæ´»æ£€ä»¥æ˜ç¡®è¯Šæ–­
                3. è¿›è¡Œä¹³è…ºè¶…å£°æˆ–é’¼é¶æ£€æŸ¥
                4. å®šæœŸéšè®¿ç›‘æµ‹
                """)
            elif probability > 0.3:
                st.warning("""
                **å»ºè®®è¿›ä¸€æ­¥è¯„ä¼°ï¼š**
                1. å’¨è¯¢ä¸“ç§‘åŒ»ç”Ÿè¿›è¡Œè¯„ä¼°
                2. è€ƒè™‘è¿›è¡Œå½±åƒå­¦æ£€æŸ¥
                3. å¯†åˆ‡è§‚å¯Ÿï¼Œ3-6ä¸ªæœˆåå¤æŸ¥
                """)
            else:
                st.info("""
                **å»ºè®®å¸¸è§„éšè®¿ï¼š**
                1. æŒ‰ç…§å¸¸è§„ç­›æŸ¥è®¡åˆ’è¿›è¡Œ
                2. ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼
                3. å®šæœŸè¿›è¡Œä¹³æˆ¿è‡ªæŸ¥
                4. å¦‚æœ‰å˜åŒ–åŠæ—¶å°±åŒ»
                """)
            
            # ------------------ ç‰¹å¾å€¼æ±‡æ€» ------------------
            with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†çš„è¾“å…¥ç‰¹å¾å€¼"):
                st.dataframe(input_df.T.rename(columns={0: 'è¾“å…¥å€¼'}))
                
        except Exception as e:
            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            st.info("è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œè¾“å…¥æ•°æ®æ˜¯å¦æ­£ç¡®ã€‚")

elif not predict_button:
    # åˆå§‹é¡µé¢
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ç‰¹å¾å€¼ï¼Œç„¶åç‚¹å‡» **'è¿›è¡Œè¯Šæ–­é¢„æµ‹'** æŒ‰é’®ã€‚")
    
    # æ˜¾ç¤ºç‰¹å¾è¯´æ˜
    if feature_info and 'feature_importance' in feature_info:
        st.subheader("æ¨¡å‹ä½¿ç”¨çš„å…³é”®ç‰¹å¾")
        importance_df = pd.DataFrame(feature_info['feature_importance'])
        st.dataframe(importance_df.sort_values('importance', ascending=False), use_container_width=True)

else:
    st.error("âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨å¹¶æ ¼å¼æ­£ç¡®ã€‚")

# é¡µè„š
st.markdown("---")
st.caption("""
*æ³¨æ„ï¼šæœ¬å·¥å…·æ—¨åœ¨è¾…åŠ©ä¸´åºŠå†³ç­–ï¼Œä¸èƒ½æ›¿ä»£æ‰§ä¸šåŒ»å¸ˆçš„ä¸“ä¸šè¯Šæ–­ã€‚æ‰€æœ‰é¢„æµ‹ç»“æœå‡åº”ç»“åˆå®Œæ•´çš„ä¸´åºŠèµ„æ–™è¿›è¡Œè§£è¯»ã€‚*
""")
