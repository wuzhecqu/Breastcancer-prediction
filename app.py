import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import json
import warnings
warnings.filterwarnings('ignore')

# ------------------ é¡µé¢é…ç½® ------------------
st.set_page_config(
    page_title="ä¹³è…ºç™Œè¯Šæ–­é¢„æµ‹ä¸è§£é‡Šç³»ç»Ÿ",
    page_icon="ğŸ©º",
    layout="wide"
)

# ------------------ åŠ è½½æ¨¡å‹å’Œè§£é‡Šå™¨ (ç¼“å­˜) ------------------
@st.cache_resource
def load_artifacts():
    """åŠ è½½æ¨¡å‹ã€æ ‡å‡†åŒ–å™¨ã€SHAPè§£é‡Šå™¨å’Œç‰¹å¾ä¿¡æ¯"""
    try:
        # åŠ è½½æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
        model = joblib.load('lightgbm_model.pkl')
        scaler = joblib.load('scaler.pkl')
        
        print(f"æ¨¡å‹ç±»å‹: {type(model)}")
        
        # åŠ è½½ç‰¹å¾ä¿¡æ¯
        try:
            with open('feature_info.json', 'r', encoding='utf-8') as f:
                feature_info = json.load(f)
            selected_features = feature_info.get('selected_features', [
                'radius_worst', 'concave points_mean', 'radius_se',
                'concavity_worst', 'area_worst', 'compactness_mean'
            ])
        except:
            # å¦‚æœfeature_info.jsonä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾
            selected_features = [
                'radius_worst', 'concave points_mean', 'radius_se',
                'concavity_worst', 'area_worst', 'compactness_mean'
            ]
            feature_info = {'selected_features': selected_features}
        
        # åˆ›å»ºèƒŒæ™¯æ•°æ®ç”¨äºSHAPè§£é‡Šå™¨
        background = np.zeros((5, len(selected_features)))
        background_df = pd.DataFrame(background, columns=selected_features)
        background_scaled = scaler.transform(background_df)
        
        # åˆ›å»ºSHAPè§£é‡Šå™¨
        explainer = shap.TreeExplainer(model, background_scaled)
        
        # è·å–æœŸæœ›å€¼
        expected_val = explainer.expected_value
        
        print(f"Expected value type: {type(expected_val)}")
        print(f"Expected value shape: {np.shape(expected_val) if hasattr(expected_val, 'shape') else 'N/A'}")
        print(f"Expected value: {expected_val}")
        
        # å¤„ç†expected_valueçš„æ ¼å¼
        if isinstance(expected_val, np.ndarray):
            if len(expected_val) == 2:
                # äºŒåˆ†ç±»ï¼Œè¿”å›ä¸¤ä¸ªå€¼çš„æƒ…å†µ
                base_value = float(expected_val[1])  # æ¶æ€§ç±»çš„åŸºç¡€å€¼
            elif len(expected_val) == 1:
                # åªæœ‰ä¸€ä¸ªå€¼çš„æƒ…å†µ
                base_value = float(expected_val[0])
            else:
                base_value = float(expected_val[0])
        elif isinstance(expected_val, (list, tuple)):
            if len(expected_val) == 2:
                base_value = float(expected_val[1])
            else:
                base_value = float(expected_val[0])
        else:
            # å•ä¸ªæ ‡é‡å€¼
            base_value = float(expected_val)
        
        print(f"Base value for SHAP: {base_value}")
        
        return model, scaler, explainer, base_value, feature_info, selected_features
        
    except Exception as e:
        print(f"Error loading artifacts: {e}")
        import traceback
        print(traceback.format_exc())
        
        # è¿”å›é»˜è®¤å€¼
        selected_features = [
            'radius_worst', 'concave points_mean', 'radius_se',
            'concavity_worst', 'area_worst', 'compactness_mean'
        ]
        return None, None, None, 0.0, {}, selected_features

# åŠ è½½æ¨¡å‹ç»„ä»¶
model, scaler, explainer, base_value, feature_info, selected_features = load_artifacts()

# ------------------ ä¾§è¾¹æ ï¼šç”¨æˆ·è¾“å…¥ ------------------
st.sidebar.header("ğŸ”¬ è¾“å…¥æ‚£è€…ç‰¹å¾å€¼")

# ä¸ºæ¯ä¸ªç‰¹å¾åˆ›å»ºè¾“å…¥æ»‘å—
feature_inputs = {}
for feat in selected_features:
    # æ ¹æ®ç‰¹å¾å®šä¹‰åˆç†çš„èŒƒå›´å’Œé»˜è®¤å€¼
    if feat == 'radius_worst':
        min_val, max_val, default_val, step_val = 10.0, 30.0, 15.0, 0.1
    elif feat == 'concave points_mean':
        min_val, max_val, default_val, step_val = 0.0, 0.2, 0.05, 0.001
    elif feat == 'radius_se':
        min_val, max_val, default_val, step_val = 0.2, 2.0, 0.5, 0.01
    elif feat == 'concavity_worst':
        min_val, max_val, default_val, step_val = 0.0, 0.5, 0.1, 0.01
    elif feat == 'area_worst':
        min_val, max_val, default_val, step_val = 500.0, 2000.0, 800.0, 10.0
    elif feat == 'compactness_mean':
        min_val, max_val, default_val, step_val = 0.05, 0.3, 0.15, 0.001
    else:
        min_val, max_val, default_val, step_val = 0.0, 1.0, 0.5, 0.01
    
    # åˆ›å»ºæ»‘å—
    value = st.sidebar.slider(
        label=f"{feat}",
        min_value=float(min_val),
        max_value=float(max_val),
        value=float(default_val),
        step=float(step_val),
        help=f"èŒƒå›´: {min_val} - {max_val}"
    )
    feature_inputs[feat] = value

st.sidebar.markdown("---")
predict_button = st.sidebar.button("ğŸš€ è¿›è¡Œè¯Šæ–­é¢„æµ‹", type="primary", use_container_width=True)

# ------------------ ä¸»é¡µé¢ ------------------
st.title("ğŸ©º ä¹³è…ºç™Œè¯Šæ–­é¢„æµ‹ä¸å¯è§£é‡Šæ€§åˆ†æ")
st.markdown("åŸºäºLightGBMæ¨¡å‹çš„ä¹³è…ºç™Œè‰¯æ¶æ€§é¢„æµ‹ç³»ç»Ÿï¼Œæä¾›SHAPå¯è§£é‡Šæ€§åˆ†æã€‚")

if predict_button and model is not None:
    with st.spinner('æ­£åœ¨åˆ†æç‰¹å¾å¹¶ç”Ÿæˆé¢„æµ‹...'):
        try:
            # 1. å‡†å¤‡è¾“å…¥æ•°æ®
            input_df = pd.DataFrame([feature_inputs])
            input_df = input_df[selected_features]  # ç¡®ä¿åˆ—é¡ºåº
            input_scaled = scaler.transform(input_df)
            
            # 2. è¿›è¡Œé¢„æµ‹ - ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„é¢„æµ‹æ–¹æ³•
            print(f"æ¨¡å‹ç±»å‹: {type(model)}")
            
            # æ–¹æ³•1ï¼šå°è¯•ä¸åŒçš„é¢„æµ‹æ–¹æ³•
            try:
                # é¦–å…ˆå°è¯•predict_probaï¼ˆé€‚ç”¨äºscikit-learnåŒ…è£…å™¨ï¼‰
                if hasattr(model, 'predict_proba'):
                    probability = model.predict_proba(input_scaled)[0][1]
                    print(f"ä½¿ç”¨ predict_proba, æ¦‚ç‡: {probability}")
                else:
                    # æ–¹æ³•2ï¼šä½¿ç”¨predictå¹¶è½¬æ¢ä¸ºæ¦‚ç‡
                    raw_pred = model.predict(input_scaled, raw_score=True)
                    print(f"åŸå§‹é¢„æµ‹å€¼: {raw_pred}")
                    
                    # å°†åŸå§‹åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆä½¿ç”¨sigmoidå‡½æ•°ï¼‰
                    if isinstance(raw_pred, np.ndarray) and len(raw_pred) > 0:
                        raw_score = raw_pred[0]
                    else:
                        raw_score = float(raw_pred)
                    
                    # Sigmoidå‡½æ•°ï¼š1 / (1 + exp(-x))
                    probability = 1 / (1 + np.exp(-raw_score))
                    print(f"è½¬æ¢åçš„æ¦‚ç‡: {probability}")
            except Exception as pred_error:
                print(f"é¢„æµ‹é”™è¯¯: {pred_error}")
                # æ–¹æ³•3ï¼šç›´æ¥ä½¿ç”¨predict
                pred = model.predict(input_scaled)
                if isinstance(pred, np.ndarray) and len(pred) > 0:
                    pred_value = pred[0]
                else:
                    pred_value = float(pred)
                
                # å¦‚æœé¢„æµ‹å€¼å·²ç»æ˜¯æ¦‚ç‡ï¼ˆåœ¨0-1ä¹‹é—´ï¼‰
                if 0 <= pred_value <= 1:
                    probability = pred_value
                else:
                    # å‡è®¾æ˜¯åˆ†ç±»æ ‡ç­¾ï¼Œè½¬æ¢ä¸ºæ¦‚ç‡
                    probability = 1.0 if pred_value > 0.5 else 0.0
            
            # ç¡®ä¿æ¦‚ç‡åœ¨åˆç†èŒƒå›´å†…
            probability = max(0.0, min(1.0, float(probability)))
            
            prediction = 1 if probability > 0.5 else 0
            prediction_label = "æ¶æ€§ (M)" if prediction == 1 else "è‰¯æ€§ (B)"
            
            print(f"æœ€ç»ˆæ¦‚ç‡: {probability}, é¢„æµ‹: {prediction_label}")
            
            # 3. è®¡ç®—SHAPå€¼
            shap_values = explainer.shap_values(input_scaled)
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"SHAP values type: {type(shap_values)}")
            
            # å¤„ç†SHAPå€¼çš„æ ¼å¼
            shap_val_for_instance = None
            
            if isinstance(shap_values, list):
                print(f"SHAP values list length: {len(shap_values)}")
                if len(shap_values) == 2:
                    # äºŒåˆ†ç±»ï¼Œæœ‰ä¸¤ä¸ªæ•°ç»„ [è‰¯æ€§SHAPå€¼, æ¶æ€§SHAPå€¼]
                    shap_val_for_instance = shap_values[1][0]  # æ¶æ€§ç±»çš„SHAPå€¼
                elif len(shap_values) == 1:
                    # åªæœ‰ä¸€ä¸ªæ•°ç»„
                    shap_val_for_instance = shap_values[0][0]
                else:
                    # å…¶ä»–æƒ…å†µ
                    shap_val_for_instance = shap_values[0][0]
            else:
                # ä¸æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                shap_val_for_instance = shap_values[0]
            
            if shap_val_for_instance is None:
                # å°è¯•ç›´æ¥è·å–
                shap_val_for_instance = explainer.shap_values(input_scaled, check_additivity=False)[0]
            
            print(f"SHAP values for instance: {shap_val_for_instance}")
            
            # ------------------ æ˜¾ç¤ºé¢„æµ‹ç»“æœ ------------------
            st.header("ğŸ“Š é¢„æµ‹ç»“æœ")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                if prediction == 1:
                    st.error(f"**é¢„æµ‹åˆ†ç±»: {prediction_label}**")
                else:
                    st.success(f"**é¢„æµ‹åˆ†ç±»: {prediction_label}**")
            
            with col2:
                st.metric(label="**æ¶æ€§æ¦‚ç‡**", value=f"{probability:.2%}")
            
            with col3:
                # é£é™©ç­‰çº§
                if probability < 0.2:
                    risk = "ä½é£é™©"
                    color = "green"
                elif probability < 0.6:
                    risk = "ä¸­é£é™©"
                    color = "orange"
                else:
                    risk = "é«˜é£é™©"
                    color = "red"
                st.markdown(f"**é£é™©ç­‰çº§**: :{color}[{risk}]")
            
            # é¢„æµ‹æ¦‚ç‡è¿›åº¦æ¡
            st.progress(float(probability), text=f"æ¶æ€§æ¦‚ç‡: {probability:.2%}")
            
            # ------------------ SHAPåŠ›åŠ›å›¾ ------------------
            st.header("ğŸ§  æ¨¡å‹å†³ç­–è§£é‡Š (SHAPåŠ›åŠ›å›¾)")
            st.markdown(f"**åŸºç¡€å€¼**: {base_value:.4f} (æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„å¹³å‡é¢„æµ‹)")
            
            # åˆ›å»ºåŠ›åŠ›å›¾
            try:
                fig, ax = plt.subplots(figsize=(10, 4))
                
                # ä½¿ç”¨force_plot
                shap.force_plot(
                    base_value=base_value,
                    shap_values=shap_val_for_instance,
                    features=input_df.iloc[0],
                    feature_names=selected_features,
                    matplotlib=True,
                    show=False,
                    text_rotation=15
                )
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.clf()
                
                st.caption("""
                **è§£è¯»**ï¼šçº¢è‰²ç‰¹å¾å°†é¢„æµ‹æ¨å‘æ¶æ€§ï¼Œè“è‰²ç‰¹å¾å°†é¢„æµ‹æ¨å‘è‰¯æ€§ã€‚
                æ‰€æœ‰ç‰¹å¾å½±å“åŠ›çš„æ€»å’Œå°†é¢„æµ‹å€¼ä»"åŸºç¡€å€¼"æ¨åˆ°äº†æœ€ç»ˆçš„é¢„æµ‹æ¦‚ç‡ã€‚
                """)
                
            except Exception as e:
                st.warning(f"æ— æ³•ç”ŸæˆSHAPåŠ›åŠ›å›¾: {e}")
                
                # æä¾›æ›¿ä»£è§£é‡Š
                st.info("""
                **ç‰¹å¾å½±å“åˆ†æ**ï¼š
                - æ­£SHAPå€¼ï¼šå¢åŠ æ¶æ€§é£é™©
                - è´ŸSHAPå€¼ï¼šé™ä½æ¶æ€§é£é™©
                - ç»å¯¹å€¼è¶Šå¤§ï¼Œå½±å“è¶Šå¼º
                """)
            
            # ------------------ ç‰¹å¾å½±å“åˆ†æ ------------------
            st.header("ğŸ“ˆ ç‰¹å¾å½±å“åˆ†æ")
            
            # åˆ›å»ºç‰¹å¾å½±å“DataFrame
            impact_df = pd.DataFrame({
                'ç‰¹å¾': selected_features,
                'SHAPå€¼': shap_val_for_instance,
                'ç‰¹å¾å€¼': input_df.iloc[0].values,
                'ç»å¯¹å½±å“': np.abs(shap_val_for_instance),
                'å½±å“æ–¹å‘': ['å¢åŠ é£é™©' if v > 0 else 'é™ä½é£é™©' for v in shap_val_for_instance]
            })
            
            # æŒ‰ç»å¯¹å½±å“æ’åº
            impact_df = impact_df.sort_values('ç»å¯¹å½±å“', ascending=False)
            
            # æ˜¾ç¤ºè¡¨æ ¼
            st.subheader("ç‰¹å¾å½±å“æ˜ç»†è¡¨")
            st.dataframe(
                impact_df[['ç‰¹å¾', 'ç‰¹å¾å€¼', 'SHAPå€¼', 'å½±å“æ–¹å‘']].style.format({
                    'ç‰¹å¾å€¼': '{:.3f}',
                    'SHAPå€¼': '{:.4f}'
                }),
                use_container_width=True
            )
            
            # ------------------ å¯è§†åŒ–ç‰¹å¾å½±å“ ------------------
            st.subheader("ç‰¹å¾å½±å“åŠ›æ¡å½¢å›¾")
            
            fig = go.Figure()
            
            # æ·»åŠ æ¡å½¢å›¾
            colors = ['red' if x > 0 else 'blue' for x in impact_df['SHAPå€¼']]
            
            fig.add_trace(go.Bar(
                x=impact_df['SHAPå€¼'],
                y=impact_df['ç‰¹å¾'],
                orientation='h',
                marker_color=colors,
                text=[f'{x:.4f}' for x in impact_df['SHAPå€¼']],
                textposition='auto',
                name='SHAPå€¼'
            ))
            
            fig.update_layout(
                title='å„ç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“ (SHAPå€¼)',
                xaxis_title='SHAPå€¼ (å¯¹æ¶æ€§æ¦‚ç‡çš„å½±å“)',
                yaxis_title='ç‰¹å¾',
                height=400,
                showlegend=False
            )
            
            # æ·»åŠ é›¶çº¿
            fig.add_vline(x=0, line_width=1, line_dash="dash", line_color="black")
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ------------------ ä¸´åºŠè§£è¯» ------------------
            st.header("ğŸ’¡ ä¸´åºŠè§£è¯»")
            
            # æ‰¾å‡ºæœ€é‡è¦çš„é£é™©å› ç´ å’Œä¿æŠ¤å› ç´ 
            top_risk = impact_df[impact_df['SHAPå€¼'] > 0].head(2)
            top_protective = impact_df[impact_df['SHAPå€¼'] < 0].head(2)
            
            col_a, col_b = st.columns(2)
            
            with col_a:
                st.subheader("ä¸»è¦é£é™©é©±åŠ¨å› ç´ ")
                if not top_risk.empty:
                    for _, row in top_risk.iterrows():
                        st.markdown(f"**{row['ç‰¹å¾']}** = {row['ç‰¹å¾å€¼']:.3f}")
                        st.markdown(f"è´¡çŒ®: **+{row['SHAPå€¼']:.4f}**")
                        if 'radius' in row['ç‰¹å¾'].lower():
                            st.markdown("åŠå¾„å€¼è¾ƒå¤§å¯èƒ½æŒ‡ç¤ºè‚¿ç˜¤ç”Ÿé•¿æ´»è·ƒ")
                        elif 'concave' in row['ç‰¹å¾'].lower():
                            st.markdown("å‡¹ç‚¹ç‰¹å¾æ˜æ˜¾å¯èƒ½æŒ‡ç¤ºç»†èƒå½¢æ€å¼‚å¸¸")
                else:
                    st.info("æœªè¯†åˆ«å‡ºæ˜æ˜¾çš„é£é™©å› ç´ ")
            
            with col_b:
                st.subheader("ä¸»è¦è‰¯æ€§æŒ‡æ ‡")
                if not top_protective.empty:
                    for _, row in top_protective.iterrows():
                        st.markdown(f"**{row['ç‰¹å¾']}** = {row['ç‰¹å¾å€¼']:.3f}")
                        st.markdown(f"è´¡çŒ®: **{row['SHAPå€¼']:.4f}**")
                        if 'area' in row['ç‰¹å¾'].lower():
                            st.markdown("é¢ç§¯ç‰¹å¾åœ¨æ­£å¸¸èŒƒå›´å†…")
                        elif 'compactness' in row['ç‰¹å¾'].lower():
                            st.markdown("ç´§è‡´åº¦æ­£å¸¸è¡¨æ˜ç»†èƒå½¢çŠ¶è§„åˆ™")
                else:
                    st.info("æœªè¯†åˆ«å‡ºæ˜æ˜¾çš„ä¿æŠ¤å› ç´ ")
            
            # å»ºè®®
            st.subheader("åç»­æ­¥éª¤å»ºè®®")
            if probability > 0.7:
                st.warning("""
                **é«˜é£é™© - å¼ºçƒˆå»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥ï¼š**
                1. ç«‹å³å’¨è¯¢ä¹³è…ºå¤–ç§‘æˆ–è‚¿ç˜¤ç§‘ä¸“å®¶
                2. è€ƒè™‘è¿›è¡Œç©¿åˆºæ´»æ£€ä»¥æ˜ç¡®è¯Šæ–­
                3. è¿›è¡Œä¹³è…ºè¶…å£°æˆ–é’¼é¶æ£€æŸ¥
                4. å®šæœŸéšè®¿ç›‘æµ‹
                """)
            elif probability > 0.3:
                st.warning("""
                **ä¸­é£é™© - å»ºè®®è¿›ä¸€æ­¥è¯„ä¼°ï¼š**
                1. å’¨è¯¢ä¸“ç§‘åŒ»ç”Ÿè¿›è¡Œè¯„ä¼°
                2. è€ƒè™‘è¿›è¡Œå½±åƒå­¦æ£€æŸ¥
                3. å¯†åˆ‡è§‚å¯Ÿï¼Œ3-6ä¸ªæœˆåå¤æŸ¥
                """)
            else:
                st.info("""
                **ä½é£é™© - å»ºè®®å¸¸è§„éšè®¿ï¼š**
                1. æŒ‰ç…§å¸¸è§„ç­›æŸ¥è®¡åˆ’è¿›è¡Œ
                2. ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼
                3. å®šæœŸè¿›è¡Œä¹³æˆ¿è‡ªæŸ¥
                4. å¦‚æœ‰å˜åŒ–åŠæ—¶å°±åŒ»
                """)
            
            # ------------------ ç‰¹å¾å€¼æ±‡æ€» ------------------
            with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†çš„è¾“å…¥ç‰¹å¾å€¼"):
                st.dataframe(input_df.T.rename(columns={0: 'è¾“å…¥å€¼'}))
                
        except Exception as e:
            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
            st.info("è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œè¾“å…¥æ•°æ®æ˜¯å¦æ­£ç¡®ã€‚")

elif not predict_button:
    # åˆå§‹é¡µé¢
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ç‰¹å¾å€¼ï¼Œç„¶åç‚¹å‡» **'è¿›è¡Œè¯Šæ–­é¢„æµ‹'** æŒ‰é’®ã€‚")
    
    # æ˜¾ç¤ºç‰¹å¾è¯´æ˜
    if feature_info and 'selected_features' in feature_info:
        st.subheader("æ¨¡å‹ä½¿ç”¨çš„å…³é”®ç‰¹å¾")
        st.write("ä»¥ä¸‹6ä¸ªç‰¹å¾ç”¨äºé¢„æµ‹ä¹³è…ºç™Œè‰¯æ¶æ€§ï¼š")
        for i, feat in enumerate(selected_features, 1):
            st.write(f"{i}. **{feat}**")

else:
    st.error("âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨å¹¶æ ¼å¼æ­£ç¡®ã€‚")

# é¡µè„š
st.markdown("---")
st.caption("""
*æ³¨æ„ï¼šæœ¬å·¥å…·æ—¨åœ¨è¾…åŠ©ä¸´åºŠå†³ç­–ï¼Œä¸èƒ½æ›¿ä»£æ‰§ä¸šåŒ»å¸ˆçš„ä¸“ä¸šè¯Šæ–­ã€‚æ‰€æœ‰é¢„æµ‹ç»“æœå‡åº”ç»“åˆå®Œæ•´çš„ä¸´åºŠèµ„æ–™è¿›è¡Œè§£è¯»ã€‚*
""")
