import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import cross_val_score, StratifiedKFold
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœéœ€è¦ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# 1. åŠ è½½æ•°æ®
train_path = r'F:\Project\Breast\train_data.csv'
val_path = r'F:\Project\Breast\validation_data.csv'

train_df = pd.read_csv(train_path)
val_df = pd.read_csv(val_path)

print("=" * 60)
print("æ•°æ®åŠ è½½å®Œæˆ")
print("=" * 60)
print(f"è®­ç»ƒé›†å½¢çŠ¶: {train_df.shape}")
print(f"éªŒè¯é›†å½¢çŠ¶: {val_df.shape}")

# 2. é€‰æ‹©æŒ‡å®šçš„6ä¸ªç‰¹å¾
selected_features = [
    'radius_worst',
    'concave points_mean',
    'radius_se',
    'concavity_worst',
    'area_worst',
    'compactness_mean'
]

print(f"\né€‰ä¸­çš„6ä¸ªç‰¹å¾:")
for i, feat in enumerate(selected_features, 1):
    print(f"{i}. {feat}")

# 3. å‡†å¤‡æ•°æ®
# åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
X_train = train_df[selected_features]
y_train = train_df['diagnosis']

X_val = val_df[selected_features]
y_val = val_df['diagnosis']

print(f"\nè®­ç»ƒé›† - ç‰¹å¾å½¢çŠ¶: {X_train.shape}, ç›®æ ‡å½¢çŠ¶: {y_train.shape}")
print(f"éªŒè¯é›† - ç‰¹å¾å½¢çŠ¶: {X_val.shape}, ç›®æ ‡å½¢çŠ¶: {y_val.shape}")

# 4. æ•°æ®æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

# 5. å®šä¹‰æ‰€æœ‰æ¨¡å‹
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
import xgboost as xgb
import lightgbm as lgb

models = {
    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(kernel='rbf', probability=True, random_state=42),
    'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000),
    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'),
    'LightGBM': lgb.LGBMClassifier(n_estimators=100, random_state=42)
}

# 6. è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             roc_auc_score, confusion_matrix, classification_report,
                             roc_curve, precision_recall_curve, auc)

results = {}
predictions = {}
probabilities = {}

print("\n" + "=" * 60)
print("æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ç»“æœ:")
print("=" * 60)

for name, model in models.items():
    print(f"\næ­£åœ¨è®­ç»ƒ {name}...")

    # è®­ç»ƒæ¨¡å‹
    model.fit(X_train_scaled, y_train)

    # é¢„æµ‹
    y_pred = model.predict(X_val_scaled)
    y_prob = model.predict_proba(X_val_scaled)[:, 1] if hasattr(model, "predict_proba") else None

    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(y_val, y_pred)
    precision = precision_score(y_val, y_pred)
    recall = recall_score(y_val, y_pred)
    f1 = f1_score(y_val, y_pred)
    roc_auc = roc_auc_score(y_val, y_prob) if y_prob is not None else None

    results[name] = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'roc_auc': roc_auc,
        'model': model
    }

    predictions[name] = y_pred
    probabilities[name] = y_prob

    print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
    print(f"  ç²¾ç¡®ç‡: {precision:.4f}")
    print(f"  å¬å›ç‡: {recall:.4f}")
    print(f"  F1åˆ†æ•°: {f1:.4f}")
    if roc_auc:
        print(f"  ROC AUC: {roc_auc:.4f}")

# 7. åˆ›å»ºç»¼åˆè¯„ä¼°æŠ¥å‘Š
results_df = pd.DataFrame(results).T
print("\n" + "=" * 60)
print("æ¨¡å‹æ€§èƒ½ç»¼åˆå¯¹æ¯”:")
print("=" * 60)
print(results_df.sort_values('accuracy', ascending=False).round(4))

# 8. å¯è§†åŒ–ï¼šROCæ›²çº¿
plt.figure(figsize=(10, 8))
colors = plt.cm.Set3(np.linspace(0, 1, len(models)))

for (name, color) in zip(models.keys(), colors):
    if probabilities[name] is not None:
        fpr, tpr, _ = roc_curve(y_val, probabilities[name])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, color=color, lw=2,
                 label=f'{name} (AUC = {roc_auc:.3f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('å‡æ­£ç‡ (False Positive Rate)')
plt.ylabel('çœŸæ­£ç‡ (True Positive Rate)')
plt.title('ROCæ›²çº¿å¯¹æ¯” (éªŒè¯é›†)')
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig(r'F:\Project\Breast\roc_curves.png', dpi=300, bbox_inches='tight')
plt.show()

# 9. å¯è§†åŒ–ï¼šPRæ›²çº¿
plt.figure(figsize=(10, 8))

for (name, color) in zip(models.keys(), colors):
    if probabilities[name] is not None:
        precision, recall, _ = precision_recall_curve(y_val, probabilities[name])
        pr_auc = auc(recall, precision)
        plt.plot(recall, precision, color=color, lw=2,
                 label=f'{name} (AUC = {pr_auc:.3f})')

# è®¡ç®—åŸºå‡†çº¿ï¼ˆæ­£ä¾‹æ¯”ä¾‹ï¼‰
baseline = np.sum(y_val) / len(y_val)
plt.axhline(y=baseline, color='k', linestyle='--', label=f'åŸºå‡†çº¿ ({baseline:.3f})')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('å¬å›ç‡ (Recall)')
plt.ylabel('ç²¾ç¡®ç‡ (Precision)')
plt.title('PRæ›²çº¿å¯¹æ¯” (éªŒè¯é›†)')
plt.legend(loc="lower left")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig(r'F:\Project\Breast\pr_curves.png', dpi=300, bbox_inches='tight')
plt.show()

# 10. å¯è§†åŒ–ï¼šæ··æ·†çŸ©é˜µï¼ˆå‰4ä¸ªæœ€å¥½æ¨¡å‹ï¼‰
best_models = results_df.sort_values('accuracy', ascending=False).head(4).index.tolist()

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.ravel()

for idx, model_name in enumerate(best_models):
    y_pred = predictions[model_name]
    cm = confusion_matrix(y_val, y_pred)

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],
                xticklabels=['è‰¯æ€§(B)', 'æ¶æ€§(M)'],
                yticklabels=['è‰¯æ€§(B)', 'æ¶æ€§(M)'])

    # æ·»åŠ æŒ‡æ ‡æ–‡æœ¬
    accuracy = results[model_name]['accuracy']
    precision = results[model_name]['precision']
    recall = results[model_name]['recall']
    f1 = results[model_name]['f1']

    info_text = f'å‡†ç¡®ç‡: {accuracy:.3f}\nç²¾ç¡®ç‡: {precision:.3f}\nå¬å›ç‡: {recall:.3f}\nF1: {f1:.3f}'
    axes[idx].text(0.5, -0.2, info_text, transform=axes[idx].transAxes,
                   ha='center', va='center', fontsize=10,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="wheat", alpha=0.5))

    axes[idx].set_xlabel('é¢„æµ‹æ ‡ç­¾')
    axes[idx].set_ylabel('çœŸå®æ ‡ç­¾')
    axes[idx].set_title(f'{model_name} æ··æ·†çŸ©é˜µ')

plt.tight_layout()
plt.savefig(r'F:\Project\Breast\confusion_matrices.png', dpi=300, bbox_inches='tight')
plt.show()


# 11. å¯è§†åŒ–ï¼šDCAå†³ç­–æ›²çº¿åˆ†æ
def calculate_net_benefit(y_true, y_prob, threshold):
    """è®¡ç®—å‡€æ”¶ç›Š"""
    y_pred = (y_prob >= threshold).astype(int)
    tp = np.sum((y_pred == 1) & (y_true == 1))
    fp = np.sum((y_pred == 1) & (y_true == 0))
    n = len(y_true)

    # å‡€æ”¶ç›Š = (TP/n) - (FP/n) * (threshold/(1-threshold))
    net_benefit = tp / n - fp / n * (threshold / (1 - threshold))
    return net_benefit


plt.figure(figsize=(10, 8))
thresholds = np.linspace(0.01, 0.99, 50)

# ç»˜åˆ¶åŸºå‡†çº¿ï¼šå…¨éƒ¨é¢„æµ‹ä¸ºé˜´æ€§ï¼ˆå…¨Bï¼‰å’Œå…¨éƒ¨é¢„æµ‹ä¸ºé˜³æ€§ï¼ˆå…¨Mï¼‰
net_benefit_all_negative = np.zeros_like(thresholds)  # å…¨éƒ¨é¢„æµ‹ä¸ºé˜´æ€§ï¼ˆå…¨Bï¼‰çš„å‡€æ”¶ç›Šä¸º0
net_benefit_all_positive = []  # å…¨éƒ¨é¢„æµ‹ä¸ºé˜³æ€§ï¼ˆå…¨Mï¼‰

for thresh in thresholds:
    # å…¨éƒ¨é¢„æµ‹ä¸ºé˜³æ€§ï¼šTP = æ‰€æœ‰å®é™…é˜³æ€§ï¼ŒFP = æ‰€æœ‰å®é™…é˜´æ€§
    tp = np.sum(y_val == 1)
    fp = np.sum(y_val == 0)
    n = len(y_val)
    nb = tp / n - fp / n * (thresh / (1 - thresh))
    net_benefit_all_positive.append(nb)

plt.plot(thresholds, net_benefit_all_negative, 'k--', label='å…¨é¢„æµ‹ä¸ºé˜´æ€§ï¼ˆå…¨Bï¼‰')
plt.plot(thresholds, net_benefit_all_positive, 'k:', label='å…¨é¢„æµ‹ä¸ºé˜³æ€§ï¼ˆå…¨Mï¼‰')

# ç»˜åˆ¶å„ä¸ªæ¨¡å‹çš„å†³ç­–æ›²çº¿
for (name, color) in zip(models.keys(), colors):
    if probabilities[name] is not None:
        net_benefits = []
        for thresh in thresholds:
            nb = calculate_net_benefit(y_val, probabilities[name], thresh)
            net_benefits.append(nb)

        plt.plot(thresholds, net_benefits, color=color, lw=2, label=name)

plt.xlabel('é˜ˆå€¼æ¦‚ç‡')
plt.ylabel('å‡€æ”¶ç›Š (Net Benefit)')
plt.title('å†³ç­–æ›²çº¿åˆ†æ (DCA)')
plt.legend(loc='upper right')
plt.grid(True, alpha=0.3)
plt.xlim([0, 1])
plt.ylim([-0.1, 0.6])
plt.tight_layout()
plt.savefig(r'F:\Project\Breast\dca_curves.png', dpi=300, bbox_inches='tight')
plt.show()

# 12. å¯è§†åŒ–ï¼šæ¨¡å‹æ€§èƒ½å¯¹æ¯”é›·è¾¾å›¾
categories = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°', 'ROC AUC']

# é€‰æ‹©å‰6ä¸ªæ¨¡å‹è¿›è¡Œé›·è¾¾å›¾å±•ç¤º
top_models = results_df.sort_values('accuracy', ascending=False).head(6).index.tolist()

fig = plt.figure(figsize=(12, 10))
ax = fig.add_subplot(111, projection='polar')

# å‡†å¤‡æ•°æ®
angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
angles += angles[:1]  # é—­åˆå›¾å½¢

for model_name in top_models:
    values = [
        results[model_name]['accuracy'],
        results[model_name]['precision'],
        results[model_name]['recall'],
        results[model_name]['f1'],
        results[model_name]['roc_auc'] if results[model_name]['roc_auc'] else 0
    ]
    values += values[:1]  # é—­åˆå›¾å½¢
    ax.plot(angles, values, 'o-', linewidth=2, label=model_name)
    ax.fill(angles, values, alpha=0.1)

ax.set_xticks(angles[:-1])
ax.set_xticklabels(categories)
ax.set_ylim(0, 1)
ax.set_title('æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾å¯¹æ¯”', pad=20)
ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
plt.tight_layout()
plt.savefig(r'F:\Project\Breast\radar_chart.png', dpi=300, bbox_inches='tight')
plt.show()

# 13. å¯è§†åŒ–ï¼šç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆå¯¹æ ‘æ¨¡å‹ï¼‰
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
tree_models = ['Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM']

for idx, model_name in enumerate(tree_models):
    ax = axes[idx // 2, idx % 2]
    model = results[model_name]['model']

    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        indices = np.argsort(importances)[::-1]

        ax.barh(range(len(selected_features)), importances[indices], align='center')
        ax.set_yticks(range(len(selected_features)))
        ax.set_yticklabels([selected_features[i] for i in indices])
        ax.set_xlabel('ç‰¹å¾é‡è¦æ€§')
        ax.set_title(f'{model_name} ç‰¹å¾é‡è¦æ€§')
    elif hasattr(model, 'coef_'):
        # å¯¹äºçº¿æ€§æ¨¡å‹
        coef = model.coef_[0]
        indices = np.argsort(np.abs(coef))[::-1]

        colors = ['red' if c < 0 else 'blue' for c in coef[indices]]
        ax.barh(range(len(selected_features)), coef[indices], color=colors, align='center')
        ax.set_yticks(range(len(selected_features)))
        ax.set_yticklabels([selected_features[i] for i in indices])
        ax.set_xlabel('ç³»æ•°å€¼')
        ax.set_title(f'{model_name} ç³»æ•°å€¼')
        ax.axvline(x=0, color='black', linewidth=0.5)

    ax.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig(r'F:\Project\Breast\feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()

# 14. ä¿å­˜ç»“æœ
output_dir = r'F:\Project\Breast\model_results_6features'
import os

os.makedirs(output_dir, exist_ok=True)

# ä¿å­˜æ¨¡å‹æ€§èƒ½ç»“æœ
results_df.to_csv(os.path.join(output_dir, 'model_performance.csv'))

# ä¿å­˜æœ€ä½³æ¨¡å‹
best_model_name = results_df['accuracy'].idxmax()
best_model = results[best_model_name]['model']

import joblib

joblib.dump(best_model, os.path.join(output_dir, 'best_model.pkl'))
joblib.dump(scaler, os.path.join(output_dir, 'scaler.pkl'))

# ä¿å­˜é¢„æµ‹ç»“æœ
predictions_df = pd.DataFrame(predictions)
predictions_df['y_true'] = y_val.values
predictions_df.to_csv(os.path.join(output_dir, 'predictions.csv'))

# ä¿å­˜ç‰¹å¾ç³»æ•°ä¿¡æ¯
coefficients = {}
for name, model in models.items():
    if hasattr(model, 'coef_'):
        coefficients[name] = model.coef_[0]
    elif hasattr(model, 'feature_importances_'):
        coefficients[name] = model.feature_importances_

if coefficients:
    coeff_df = pd.DataFrame(coefficients, index=selected_features)
    coeff_df.to_csv(os.path.join(output_dir, 'feature_coefficients.csv'))

# 15. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
print("\n" + "=" * 60)
print("è¯¦ç»†åˆ†ææŠ¥å‘Š:")
print("=" * 60)

print(f"\nğŸ¯ æœ€ä½³æ¨¡å‹: {best_model_name}")
print(f"   éªŒè¯é›†å‡†ç¡®ç‡: {results[best_model_name]['accuracy']:.4f}")
print(f"   ROC AUC: {results[best_model_name]['roc_auc']:.4f}")

print(f"\nğŸ“Š 6ä¸ªç‰¹å¾çš„é‡è¦æ€§æ€»ç»“:")
print("   æ­£ç³»æ•°ç‰¹å¾ï¼ˆä¸æ¶æ€§ç›¸å…³ï¼‰:")
print("   1. radius_worst (ç³»æ•°: +0.508) - æœ€å·®åŠå¾„ï¼Œæœ€é‡è¦çš„æ¶æ€§æŒ‡æ ‡")
print("   2. concave points_mean (ç³»æ•°: +0.137) - å¹³å‡å‡¹ç‚¹æ•°é‡")
print("   3. radius_se (ç³»æ•°: +0.133) - åŠå¾„æ ‡å‡†è¯¯")
print("   4. concavity_worst (ç³»æ•°: +0.103) - æœ€å·®å‡¹åº¦")

print("\n   è´Ÿç³»æ•°ç‰¹å¾ï¼ˆä¸è‰¯æ€§ç›¸å…³ï¼‰:")
print("   5. area_worst (ç³»æ•°: -0.323) - æœ€å·®é¢ç§¯")
print("   6. compactness_mean (ç³»æ•°: -0.147) - å¹³å‡ç´§è‡´åº¦")

print(f"\nğŸ“ˆ ä¿å­˜çš„æ–‡ä»¶:")
print(f"   1. æ¨¡å‹æ€§èƒ½: {output_dir}\\model_performance.csv")
print(f"   2. æœ€ä½³æ¨¡å‹: {output_dir}\\best_model.pkl")
print(f"   3. æ ‡å‡†åŒ–å™¨: {output_dir}\\scaler.pkl")
print(f"   4. é¢„æµ‹ç»“æœ: {output_dir}\\predictions.csv")
print(f"   5. ç‰¹å¾ç³»æ•°: {output_dir}\\feature_coefficients.csv")

print(f"\nğŸ–¼ï¸ å¯è§†åŒ–å›¾è¡¨:")
print("   1. ROCæ›²çº¿: F:\\Project\\Breast\\roc_curves.png")
print("   2. PRæ›²çº¿: F:\\Project\\Breast\\pr_curves.png")
print("   3. æ··æ·†çŸ©é˜µ: F:\\Project\\Breast\\confusion_matrices.png")
print("   4. DCAæ›²çº¿: F:\\Project\\Breast\\dca_curves.png")
print("   5. é›·è¾¾å›¾: F:\\Project\\Breast\\radar_chart.png")
print("   6. ç‰¹å¾é‡è¦æ€§: F:\\Project\\Breast\\feature_importance.png")

print("\n" + "=" * 60)
print("æ‰€æœ‰æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼")
print("=" * 60)